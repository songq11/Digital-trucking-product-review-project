{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93800412-e80d-405f-8a8e-82ab6f1be884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning:\n",
    "# 1. [Done] Data cleaning: Take a closer look at text with keyword \"平台\"\n",
    "# 2. Clean timestamp\n",
    "# 3. [Done] More data cleaning: combine title and description only when title != description\n",
    "# 4. HanLP summarize topics and keywords--use this to filter out nonrelevant documents\n",
    "# 5. [Done] Deal with links in descriptions\n",
    "# 6. [Done] Deal with noises (e.g. \\n)\n",
    "\n",
    "\n",
    "# To do:\n",
    "# 1. [Done] Keywords to check: \"新能源\" \n",
    "# 2. [Done]'江淮','轻卡', '中卡', '重卡', '冷藏车'，'解放', '购车', '重汽', '牵引车', '厢式货车','轮胎', '发动机', '欧曼'\n",
    "# # # check these keywords again\n",
    "# # # 以上关键词下有大量无用信息，但是也有很多涉及到‘货拉拉’等平台的讨论。比如跑货拉拉买什么车好。这个问题说明司机为了平台专门买车。\n",
    "# # # 所以这几个词不能全部drop，要进一步考虑如何filter掉仅仅讨论车的内容。\n",
    "# # # 另外可以去除涉及到这几个关键词的长度过长的帖子。\n",
    "# # # 有没有自动判定是广告的package？\n",
    "# 3. [Done] Check pattern: '拉货|货源|网络平台|跑平台|找货|平台接单|货运配送信息平台|货运平台|走平台|APP|货运信息发布平台|货运APP|数字化货运'\n",
    "# 4. [Done] Check pattern = r'(?=.*卡车之家)(?=.*平台)(?=.*感谢)' \n",
    "# 5. [Done] 检查平台名称的昵称，如货**，祸啦啦，yunmanman, ‘货 车 帮’etc\n",
    "# 6. [Done] join title and description when title != description\n",
    "# 7. [Done] Deal with links in 'description'\n",
    "# 8. Retrieve from drop_df  if keyword != 平台\n",
    "# 9. [Done] Define as safe_data if title includes keywords but description is empty\n",
    "# 10. [Done] fix new line (\\r\\n) \n",
    "# 11. [Done] Fix other noises, e.g. #, extra space  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05270f74-2a52-40f5-a2fc-a3ffe3badca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861a40c-2dae-4baf-b7b3-9e52540cbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('RawData.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9479f-87c0-4b64-b75b-c65d4d812bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'tid' has duplicated values\n",
    "df['tid'] = pd.to_numeric(df['tid'])\n",
    "df['tid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9e09a-6fdc-418f-b51e-02fe19a8c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates(subset=['tid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0ca23-6854-407d-b899-26bee1b78c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing \"直播平台\" and more \n",
    "dropped_keywords = r'直播平台|亚马逊平台|卖车平台|Temu平台'  \n",
    "contains_dropped_keywords = df['title'].str.contains(dropped_keywords, case=False, na=False)|df['description'].str.contains(dropped_keywords, case=False, na=False)\n",
    "df = df[~contains_dropped_keywords]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c16cf3-76df-4e80-97b9-56b653b962c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('isHot', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda74ce-4c15-45c7-8a98-091cd75ec805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with links in 'description'\n",
    "\n",
    "# Regular expression pattern for matching URLs\n",
    "url_pattern = r'(http[s]?://[^\\s]+)'\n",
    "def extract_urls(x):\n",
    "    return re.findall(url_pattern, x)\n",
    "\n",
    "df['links'] = df['description'].apply(extract_urls)\n",
    "\n",
    "# Remove URLs from the original column\n",
    "df['description'] = df['description'].str.replace(url_pattern, '', regex=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6eac9-b222-457e-a7e0-5fbd0bf519f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop new line signs \n",
    "df['description'] = df['description'].replace(r'\\r\\n|\\r|\\n', '', regex=True)\n",
    "print(df['description'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4745759-ed6a-4b96-bda9-6703951545ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop noises (e.g. #)\n",
    "df['description'] = df['description'].replace(r'#', '', regex=True)\n",
    "df['title'] = df['title'].replace(r'#', '', regex=True)\n",
    "\n",
    "# Remove all spaces\n",
    "df['description'] = df['description'].str.replace(' ', '', regex=True)\n",
    "df['title'] = df['title'].str.replace(' ', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3afe5-a864-46e5-a207-c0ea6c7c8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and description into full text when text != description\n",
    "\n",
    "def join_des_title(row):\n",
    "    title = row['title']\n",
    "    des = row['description']\n",
    "    if title != des:\n",
    "        fulltext = title + des\n",
    "    else:  \n",
    "        fulltext = title\n",
    "    return fulltext  # Explicitly return the combined value.\n",
    "\n",
    "# Apply the function across each row (axis=1)\n",
    "df['fulltext'] = df.apply(join_des_title, axis=1)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af0443-9575-4006-b834-2773eb6076d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are rows that do not need to drop for certain\n",
    "safe_words = r'运满满|货车帮|满帮|货拉拉'\n",
    "safe_data = df[df['fulltext'].str.contains(safe_words)]\n",
    "safe_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f2b06-fc40-43ce-aa07-e61af9fe2511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create drop_df to store hand-labeled data\n",
    "drop_rows = [4206269, 4189528, 4199761, 4198174, 4158945, 4160055, 4156021, 4180746, 4153232, 4150274,\n",
    "            4140355, 4144839, 4140023, 4177614, 4140098, 4140661, 4118098, 4198331, 4112225, 4155607,\n",
    "            4116943, 4127864, 4154871, 4230073, 4223087, 4147394, 4092950, 4225032, 4224797, 4201612, \n",
    "            4221406, 4230074, 4094530, 4208279, 4169342, 4224947, 4221507, 4218582, 4186372, 4138462, \n",
    "            4160339, 4152716, 4167395, 4131743, 4184764, 4135173, 4097525, \n",
    "            4225765, 4062857, 4194521, 4062857, 4021542, 4103677, 3912846,3940659,4106426,3843810,4019347,4063065,4005551,4009488,\n",
    "             3955223, 3958849, 4006490, 3948245, 3795755, 3723194, 3879128, 3882277, 3871359, 3999604, 4021166, 3993411, 3876568,\n",
    "             4019496, 3951974, 3937517, 3936127, 3924264, 3953073, 3813832, 3817042, 3857828, 3791837, 3791837, 3634110, 3787212,\n",
    "             3909370, 3798534, 3700722, 3853733, 3870739, 3860417, 3705489, 3724751, 3793107, 3732709, 3820384, 3799585, 3465302, \n",
    "             3779986, 3723896, 3680179, 3715496, 3654687, 3782826, 3667343, 3670672, 3640110, 3662713, 3681488, 3653932, 3458447,\n",
    "             3617418, 3622289, 3276495, 3063478, 3514443, 3412827, 3453601, 3501039, 3445889, 3567600, 3612575, 3388163, 3346517,\n",
    "             3599728, 3285466, 3394530, 3284597, 3254212, 2566325, 3178290, 3146624, 3166987, 2598661, 3125868, 3339152, 3342357,\n",
    "             3083526, 3054823, 2478794, 3134632, 2914100, 3098460, 3143003, 2881666, 2929605, 3122733, 2721389, 2891674, 3184403,\n",
    "             2956741, 2727408, 3037502, 2549572, 4138813, 4147394, 4136990, 4138462, 4160339, 4152716, 4167395, 4131743, 4184764, \n",
    "             4135173, 4138814, 4097525, 4076294, 4139143, 4074414, 4119061, 4032570, 4063539, 4046712]  # manually selected with keyword '卡车之家' and '平台'\n",
    "\n",
    "drop_df = df[df['tid'].isin(drop_rows)]\n",
    "# drop_df.to_excel('dropped_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e48af-cfe6-4a96-bb9c-63c65fee2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify authors to drop\n",
    "drop_authors = ['淡定人生jewv', '大力士', '辽宁卡友zgqkte', '重庆卡友lrezaq', '卡家小林', '卡家木木', '卡家小白兔', '卡家小双',\n",
    "                '江铃轻卡家族', '山东卡友xmwvlo', '山东卡友dahyjv', '山东卡友cqtwzm', '山东卡友zqhydb', '卡家小太阳', '卡家大鹏', '卡家短视频', \n",
    "                '卡家小新', '卡家小官', '卡家大白', '卡家商城—大白', '卡家小肉丸', '卡家小贝壳', '卡家运力', '卡家小编', '卡家约稿君', \n",
    "                '卡家二手车', '卡家大鑫', '卡家小威', '卡家小米', 'kayouLlvL', '⒉冄1⒋号', '卡车之家商城'] \n",
    "drop_df = pd.concat([drop_df, df[df['author'].isin(drop_authors)]])\n",
    "\n",
    "# '卡家小白兔' keep 'tid' in [4078138, 4071625, 4073974, 4073597, 4068177, 4050297], but need to re-collect content data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341acdb-df5d-44f0-b9a8-a8a7e429fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3f03c-032e-4e5a-870d-a5540817caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove these rows of safe_data and drop_df to simplify clean_data a bit\n",
    "uncertain_data = pd.DataFrame()\n",
    "for i in df['tid']:\n",
    "    if i not in (list(drop_df['tid']) + list(safe_data['tid'])):\n",
    "        uncertain_data = pd.concat([uncertain_data, df[df['tid'] == i]])\n",
    "\n",
    "uncertain_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6ac2d-c9ad-473a-8fbb-26eb697679cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_keywrds = r'急聘|卡车之家商城|抖音平台'\n",
    "drop_df = pd.concat([drop_df, uncertain_data[uncertain_data['fulltext'].str.contains(drop_keywrds, regex=True)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3db67d-b022-4b7f-ac9c-c9186521aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = r'(?=.*卡车之家)(?=.*平台)(?=.*感谢)'\n",
    "drop_df = pd.concat([drop_df, uncertain_data[uncertain_data['description'].str.contains(test_1, regex=True, flags=re.DOTALL)]])\n",
    "drop_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e0259-a1d5-43fc-be7c-51e3f447dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here are all the patterns that can be dropped:\n",
    "test_0 = r'(?=.*(?:江淮|购车|欧曼|一汽解放|重汽))(?=.*(?:重卡|轻卡|中卡|冷藏车|牵引车|厢式货车|轮胎|发动机|新能源))'\n",
    "drop_df = pd.concat([drop_df, uncertain_data[uncertain_data['description'].str.contains(test_0, regex=True, flags=re.DOTALL)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d019c7-c31f-47ec-a7b4-24de569d0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all '江淮' except for which containing words like '拉货|货源|网络平台|跑平台|找货'\n",
    "include_words = r'江淮'\n",
    "exclude_words = r'跑平台|跑货车'\n",
    "\n",
    "# Select rows that contain the inclusion keyword and do not contain the exclusion keyword\n",
    "filtered_rows = uncertain_data[(uncertain_data['description'].str.contains(include_words)) & (~uncertain_data['description'].str.contains(exclude_words))]\n",
    "\n",
    "drop_df = pd.concat([drop_df, filtered_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2aa290-05b8-4462-b89a-6de3449872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows that contain at least two of the above keywords\n",
    "strings_to_search = ['设备', '东风', '江铃', '江淮', '购车', '欧曼', '一汽解放', '重汽', '新能源', '重卡', '轻卡', '中卡', \n",
    "                     '冷藏车', '牵引车', '厢式货车', '轮胎', '发动机']\n",
    "\n",
    "# Count occurrences and filter rows\n",
    "uncertain_data['match_count'] = uncertain_data['description'].apply(lambda x: len([match for match in strings_to_search if match in x]))\n",
    "filtered_df = uncertain_data[uncertain_data['match_count'] >= 2]\n",
    "\n",
    "# print(len(filtered_df['description']))\n",
    "# print(filtered_df['description'])\n",
    "\n",
    "drop_df = pd.concat([drop_df, filtered_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85394caf-ed61-46d8-b8c6-34c5ee463b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 拉货|货源|网络平台|跑平台|找货|平台接单|货运配送信息平台|货运平台|走平台|APP|货运信息发布平台|货运APP|数字化货运\n",
    "\n",
    "safe_words = safe_words + r'数字化货运|货运APP|走平台|货运平台|平台接单|找货|跑平台|网络平台|货源|拉货'\n",
    "good_text = uncertain_data[uncertain_data['fulltext'].str.contains(safe_words, regex=True)]\n",
    "safe_data = pd.concat([safe_data, good_text])\n",
    "safe_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abb043-23bb-4a73-9d40-31a5482ad832",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_title = r'运费冻结|平台作梗|试点平台|货运平台|找货平台|车货匹配平台'\n",
    "good_title = uncertain_data['title'].str.contains(safe_title, regex=True)\n",
    "desc_empty = uncertain_data['description']==''\n",
    "\n",
    "safe_data = pd.concat([safe_data, uncertain_data[desc_empty & good_title]])\n",
    "drop_df = pd.concat([drop_df, uncertain_data[desc_empty & (~good_title)]])\n",
    "print(drop_df.info())\n",
    "print(safe_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07fcde-027e-4e8a-ad86-72df4118e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_ctgry = uncertain_data[uncertain_data['keyword']=='满帮']\n",
    "safe_data = pd.concat([safe_data, safe_ctgry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae5a05-51d0-4a5b-a4ab-7d67865085c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ctgry = uncertain_data[(uncertain_data['keyword']=='货车帮')|(uncertain_data['keyword']=='货拉拉')]\n",
    "drop_df = pd.concat([drop_df, drop_ctgry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4479fa9-8fdf-4b7e-b420-c4ba37a836f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(uncertain_data['topicName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110447cc-1266-4c5d-9e74-769c110843d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_topic = ['下半年运价有望好转吗？',  '九月发帖不停，赢车模、卫衣', '买新车的来报到', '今年的运费咋样了？', '低价货拉还是不拉？',\n",
    "              '你对货运平台的看法', '你对货运环境都有哪些意见?',  '你用过哪些网络货运平台？', '你见过哪些新型货运骗局？',\n",
    "              '你那里运费上涨了吗？',  '冬季行车需要注意些什么？',  '卡友有话说（我为行业发声）', '卡友闲暇时光秀', '如何看待“货车超载入刑”？', \n",
    "              '平台冻结运费合理吗？', '庆中秋共团圆',  '我在行业这些年',  '我对2021货运行业的看法',  '我对货运平台的看法',  '我的拉散货经历', \n",
    "              '扒一扒货运平台的套路', '晒油耗，谈省油', '疫情时代，各地的运费涨了吗？', '祥菱大熊猫的动力有多大？',  '给新手司机的经验之谈', \n",
    "              '老司机平常找货的渠道有哪些？', '老赖货主扣运费咋办？',  '货拉拉陷“停运”风波', '货运平台计价规则公开？', '购车应该规避哪些坑？',\n",
    "              '运费一降再降，你怎么看', '香菱角的致富理想型' ]\n",
    "\n",
    "safe_topic_data = uncertain_data[uncertain_data['topicName'].isin(safe_topic)]\n",
    "safe_data = pd.concat([safe_data, safe_topic_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ec004-acfd-4eec-b438-759164f33ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_topic = [' 疫情下的卡车司机', '2023年定个小目标', '38妇女节·爱在卡嫂', '618晒单赢总成、冰箱、坐垫', '【迷惑】新能源选车攻略',\n",
    " '你对江淮德沃斯中卡的真感受', '你期待柔性执法吗？', '你见过新能源有啥政策？', '信息广场', '发帖七天乐，赢车模、定制雨衣',\n",
    " '发帖有礼：挑战8月榜单', '哪里行程码带星？要通行证？', '喜迎新春7天乐', '我的第一辆车是，怎么买的它？', '拍出我的货运路',\n",
    " '新手上路注意事项', '晒出你的卡家好物', '晒出我拉的货', '晒晒我的驾驶室', '欢度国庆，献礼73周年', '正在发生的事', '每日发帖赢好礼',\n",
    " '每日维修保养小记', '说说你认为值得买的车', '谈谈你对LNG卡车的了解', '货车维修被坑记', '货运人的端午节', '货运市场会迎来春天吗？',\n",
    " '那些年，我开过的解放车', '重卡+玉柴为啥这么省油', '金秋收获季，发帖赢冲锋衣', '领航卡车·美好生活']\n",
    "bad_topic_data = uncertain_data[uncertain_data['topicName'].isin(bad_topic)]\n",
    "drop_df = pd.concat([drop_df, bad_topic_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6dd02-9768-4b7f-a4a6-d54084e6d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_words = \"江淮|购车|欧曼|一汽解放|重汽|新能源|重卡|轻卡|中卡|冷藏车|牵引车|厢式货车|轮胎|发动机\"\n",
    "drop_word_title = r'展览|博览会|国际|设备|自卸车|底盘|抑尘车|江铃|江淮|欧曼|三一江山|东风|金杯|洒水车|NQI|侧翻|重汽|重卡|中卡|轻卡|牵引车|极氪|法士特|福田|长安|升降平台|新朱宏|骏铃|新能源|支撑平台|租赁平台'\n",
    "drop_df = pd.concat([drop_df, uncertain_data[uncertain_data['title'].str.contains(drop_word_title, regex=True)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f8472-73ed-4a28-a8d4-8a97d54c37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_keywrds = r'欧曼|一汽解放|重汽|重卡|中卡|轻卡|牵引车|洒水车|东风|侧翻|法士特|福田|长安|升降平台|骏铃|支撑平台|租赁平台|抑尘车|底盘|自卸车'\n",
    "drop_df = pd.concat([drop_df, uncertain_data[uncertain_data['description'].str.contains(drop_keywrds, regex=True)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eeaedd-b8f1-4cb2-bc91-14b8da030466",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = uncertain_data[uncertain_data['description'].apply(lambda x: len(x) > 1000)]\n",
    "drop_df = pd.concat([drop_df, long_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566eed0e-08e9-4266-8813-429756403f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updata uncertain_data--run this every time after updating drop_df\n",
    "uncertain_data = pd.DataFrame()\n",
    "for i in df['tid']:\n",
    "    if i not in (list(drop_df['tid']) + list(safe_data['tid'])):\n",
    "        uncertain_data = pd.concat([uncertain_data, df[df['tid'] == i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70038b-45cd-4bf6-b5a4-ea5d260d0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "uncertain_data = uncertain_data.drop_duplicates(subset=['tid'])\n",
    "safe_data = safe_data.drop_duplicates(subset=['tid'])\n",
    "drop_df = drop_df.drop_duplicates(subset=['tid'])\n",
    "\n",
    "print(len(uncertain_data['tid']))\n",
    "print(len(safe_data['tid']))\n",
    "print(len(drop_df['tid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f067b-4552-44b7-89e7-b9872a29acb0",
   "metadata": {},
   "source": [
    "# More cleaning with GPT results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb583fd-629a-4b4b-9482-9dc77deb0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in chatgpt classified data\n",
    "import json\n",
    "from pathlib import Path\n",
    "fpath = Path('data-cleaning-uncertain-by-chatgpt.json')\n",
    "gpt_data = json.loads(fpath.read_text())\n",
    "gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b13838-d37f-4502-bac8-5f3e53468ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df = pd.DataFrame.from_dict(gpt_data, orient='index', columns=['reason', 'result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000b306-6eb9-45cf-a69d-abc1b8786334",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df.reset_index(inplace=True)\n",
    "gpt_df.rename(columns={'index': 'tid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc00eeb-fbe0-426c-b898-862834160b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df['tid'] = pd.to_numeric(gpt_df['tid'])\n",
    "gpt_df.info()\n",
    "gpt_df['tid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383087da-16e0-49ca-9f0a-7e0cfa2070c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with safe_data if result == 1, keep the result column\n",
    "# Merge with drop_data if result == 0, keep the result column\n",
    "\n",
    "gpt_keep = pd.DataFrame()\n",
    "gpt_drop = pd.DataFrame()\n",
    "for i in range(len(gpt_df)):\n",
    "    result = gpt_df.iloc[i]['result']\n",
    "    if result == 1:\n",
    "        gpt_keep = pd.concat([gpt_keep, uncertain_data[uncertain_data['tid'] == gpt_df.iloc[i]['tid']]])      \n",
    "    if result == 0:\n",
    "        gpt_drop = pd.concat([gpt_drop, uncertain_data[uncertain_data['tid'] == gpt_df.iloc[i]['tid']]])\n",
    "        \n",
    "        \n",
    "print(gpt_keep.info())\n",
    "print(gpt_drop.info())\n",
    "\n",
    "safe_data = pd.concat([safe_data, gpt_keep])\n",
    "drop_df = pd.concat([drop_df, gpt_drop])\n",
    "print(safe_data.info())\n",
    "print(drop_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e04787-784f-42dc-8245-5c0afa1bfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updata uncertain_data--run this every time after updating drop_df\n",
    "uncertain_data = pd.DataFrame()\n",
    "for i in df['tid']:\n",
    "    if i not in (list(drop_df['tid']) + list(safe_data['tid'])):\n",
    "        uncertain_data = pd.concat([uncertain_data, df[df['tid'] == i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5f869-7115-4409-98c3-4103540e8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d705f8-f4dd-4639-a6bb-78ac6582dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_data = safe_data.drop(['match_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485150c-4c7a-4480-8710-d7b2c72b21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save safe_data as clean_data_final\n",
    "safe_data.to_parquet('clean_data_final.parquet')\n",
    "drop_df.to_parquet('dropped_data_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af70eb-c27c-4304-9c31-fd9cb2040e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
