{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231440d-7357-407e-99a6-d3bf6641fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_parquet('../processed_data/final_data_2015-23')\n",
    "for i in ['clean_tok']:\n",
    "    df[i] = df[i].apply(lambda f: f.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e99217-428d-4179-bb6d-d3f27349629c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497dfb6-2ba5-4f7a-8680-de03ac5ef5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove more chaos by checking word frequency \n",
    "words_des = sum(df['clean_tok'], [])\n",
    "from collections import Counter\n",
    "ct = Counter(words_des)\n",
    "sorted_ct = ct.most_common()\n",
    "for word, count in sorted_ct:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fb3b1-9c60-4b65-9591-c11590cb4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chaos = ['„Äê', '„Äë', '...', 'Ôºâ', 'Ôºà', '#', '[', ']', 'ÔºÅÔºÅÔºÅ', ',', '‚Äî‚Äî', '-', 'ÔºÅÔºÅ', '*', '.', '‚Ä¶‚Ä¶', '+',\n",
    "        '!', ':', '/', '--', '|', '(', '~', '‚Ä¶', '‚Äî', ')', 'ÔΩû', 'ÔºüÔºüÔºü', ';', '¬∑', 'ÔºüÔºü', '„ÄÇ„ÄÇ„ÄÇ', '„ÄÇ„ÄÇ'\n",
    "        'ÔºÅÔºÅÔºÅÔºÅ', '---', '„Äå', '„Äç', 'quot', '..', '‚óè', '**', '‚ñé', '....', 'üòú' ]\n",
    "\n",
    "def remove_chaos(word_list):\n",
    "    clean_words = []\n",
    "    for word in word_list:\n",
    "        if word not in chaos:\n",
    "            clean_words.append(word)\n",
    "    return clean_words\n",
    "\n",
    "df['clean_tok'] = df['clean_tok'].apply(remove_chaos)\n",
    "any(i is None for i in df['clean_tok'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e47b4-cca2-466f-b43f-eb33dcc8301f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using SnownLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a50b7-c3d7-4361-af19-b1d44ce1fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP\n",
    "from snownlp import sentiment\n",
    "def get_sentiment(text):\n",
    "    if len(text) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return SnowNLP(text).sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca9f8a-b4a3-4254-9e05-a8d406432714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate by joining tokens back together\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "df['joined_tok'] = df['clean_tok'].progress_apply(lambda tokens: ''.join(tokens))\n",
    "df['sentiment'] = df['joined_tok'].progress_apply(get_sentiment)\n",
    "df['sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b4d00-74e7-4ebb-a64b-c41461a0a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../processed_data/with_sentiment.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc735581-cb31-4880-8a3b-112e54991e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which of \"filtered_title\" are empaty \n",
    "df['t_empty'] = df['filtered_title'].apply(lambda x: len(x) == 0)\n",
    "print(df['t_empty'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd729b-f437-4ef7-9219-82a6b7910dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['sentiment']>0.5).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4335ac-dfdf-4df1-9c53-15a815e9b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7494233-c608-40a8-8ef7-b7b093e737a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['sentiment']<0.2).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb06fc9-9deb-4c7f-9c01-9674d69ecb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check top word counts with sentiment < 0.2\n",
    "from collections import Counter\n",
    "neg_stmt = df[df['sentiment']<0.2]\n",
    "neg_stmt_words = sum(neg_stmt['clean_tok'], [])\n",
    "ct_neg_words = Counter(neg_stmt_words)\n",
    "print(ct_neg_words.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0d8c4-73a1-4093-a9b2-c112d97bf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average (or median) sentiment over years\n",
    "# df['year'] = df['date'].apply(lambda x: x[:4])\n",
    "# df['year'] = pd.to_numeric(df['year'])\n",
    "\n",
    "yearly_mean_sentiment = {}\n",
    "for year in sorted(df['year'].unique()):\n",
    "    df_year = df[df['year'] == year]\n",
    "    mean_stmt_year = df_year['sentiment'].mean()\n",
    "    yearly_mean_sentiment[year] = mean_stmt_year\n",
    "\n",
    "print(yearly_mean_sentiment)\n",
    "\n",
    "# Plot the results\n",
    "years = list(yearly_mean_sentiment.keys())\n",
    "mean_sentiments = list(yearly_mean_sentiment.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(years, mean_sentiments, marker='o')\n",
    "plt.title('Mean Sentiment Over Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Sentiment')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c81fa-0102-40fc-b527-47e0cfda3a3f",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9820cf-5336-41c0-b84b-560824c8a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_df=0.9, min_df=2, tokenizer=lambda x: x, preprocessor=lambda x: x)\n",
    "dtm = cv.fit_transform(df['clean_tok'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af537e-1b6f-4ae4-89a5-6693f585c55a",
   "metadata": {},
   "source": [
    "### LDA in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd127a63-6963-4631-9439-645eecea4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffe474-5419-4596-b8c6-194474d23341",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7011d7-045d-43dc-8e4b-38867ac91587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the volucabulary of words\n",
    "cv.get_feature_names_out()[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441e9df-c0c7-44e6-9075-30d36aef9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the topics\n",
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5f2e9-3a3e-4c17-8dd1-0db810a44f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the highest probability words per topic\n",
    "single_topic = LDA.components_[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f85acb-6f2a-47b1-a6f7-bc80be680c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argsort --> index positions sorted from least to greast\n",
    "single_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e36a8-7929-4691-9ffc-588b92a97533",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_twenty_words = single_topic.argsort()[-20:] # grad the last 20 values  .argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fae5e8-8ebd-40c5-89de-0bd54220b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in top_twenty_words:\n",
    "    print(cv.get_feature_names_out()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860e484-d319-4c27-8758-6d17b4b50654",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,7):\n",
    "    print(f\"The top 15 words for topic #{i}\")\n",
    "    for index in LDA.components_[i].argsort()[-20:]:\n",
    "        print(cv.get_feature_names_out()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab2055-2f4c-4870-a5ca-8f0c0d294ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3eada-2a43-474b-aea7-ffb23866cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results.round(2) #shows probability of each topic for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c37d4-f9f7-4567-bcfc-e0aa99053177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d19ed8-0730-489f-9dee-35dc5abd0b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a column to assign topics to the dataframe\n",
    "df['topic_lda'] = topic_results.argmax(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26831ef0-7735-48cd-bc72-ae5f742f0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[1]['fulltext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705a46f-ddcd-4456-9ca2-0240d8bea798",
   "metadata": {},
   "source": [
    "### LDA using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7840d-960a-449e-8bff-f1de228e8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code learned from: https://zhuanlan.zhihu.com/p/133779883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b3bcf-5558-4113-b421-ba0811df983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe8a49-b8c2-47d5-a36e-8763138a5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1079b-9f0b-4a9c-be2b-7fefdb5cad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(df['clean_tok'])\n",
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411cbca2-f06f-4ba2-88f0-efb89d859452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞ÜÂ≠óÂÖ∏ËΩ¨Êç¢‰∏∫ËØçË¢ã,‰∏∫ÊñáÊ°£‰∏≠ÁöÑÊØè‰∏Ä‰∏™ÂçïËØçÂàõÂª∫ÂîØ‰∏ÄÁöÑID\n",
    "corpus = [id2word.doc2bow(token) for token in df['clean_tok']]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c137c10-42d3-490a-85a5-d9acd1f929fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂèØÈÄöËøáÂ¶Ç‰∏ãÈ¢ÑÊúüÊü•ËØ¢idÂØπÂ∫îÁöÑËØç\n",
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c8514-5b73-4bb4-bd99-e039df0bea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âª∫Á´ãLDAÊ®°Âûã\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                id2word=id2word,\n",
    "                num_topics=10,\n",
    "                random_state=100,\n",
    "                update_every=1,\n",
    "                chunksize=100,\n",
    "                passes=10,\n",
    "                alpha='auto',\n",
    "                per_word_topics=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680fdfc-c417-41f4-90aa-f9775dfc16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰∏äËø∞LDAÊ®°ÂûãÁî±10‰∏™‰∏çÂêåÁöÑ‰∏ªÈ¢òÊûÑÂª∫ÔºåÂÖ∂‰∏≠ÊØè‰∏™‰∏ªÈ¢òÊòØÂÖ≥ÈîÆÂ≠óÁöÑÁªÑÂêàÔºåÂπ∂‰∏îÊØè‰∏™ÂÖ≥ÈîÆÂ≠óÂØπ‰∏ªÈ¢òË¥°ÁåÆ‰∏ÄÂÆöÁöÑÊùÉÈáçÔºåÊùÉÈáçÂèçÂ∫î‰∫ÜÂÖ≥ÈîÆÂ≠óÂØπ‰∏ª‰ΩìÁöÑË¥°ÁåÆÁ®ãÂ∫¶„ÄÇ\n",
    "# num_word‰ª£Ë°®ÊØè‰∏™‰∏ªÈ¢òÁöÑÂÖ≥ÈîÆÂ≠óÊï∞\n",
    "pprint(lda_model.print_topics(num_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20524bd-8310-4940-8db9-9a32ade66893",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ê®°ÂûãÂ§çÊùÇÂ∫¶Âíå‰∏ªÈ¢ò‰∏ÄËá¥ÊÄßÊèê‰æõ‰∫Ü‰∏ÄÁßçÊñπ‰æøÁöÑÊñπÊ≥ïÊù•Âà§Êñ≠ÁªôÂÆö‰∏ªÈ¢òÊ®°ÂûãÁöÑÂ•ΩÂùèÁ®ãÂ∫¶„ÄÇ\n",
    "ÁâπÂà´ÊòØ‰∏ªÈ¢ò‰∏ÄËá¥ÊÄßÂæóÂàÜÊõ¥ÊúâÂ∏ÆÂä©„ÄÇ\n",
    "'''\n",
    "# def model():\n",
    "# Compute Perplexity Ê®°ÂûãÂ§çÊùÇÂ∫¶\n",
    "print('Perplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['clean_tok'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda) # ‰∏ªÈ¢ò‰∏ÄËá¥ÊÄßÂæóÂàÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2afe16-b45b-427c-96f5-a0f8a41cf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂØªÊâæLDAÁöÑÊúÄ‰Ω≥‰∏ªÈ¢òÊï∞\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "for num_topics in range(2,15,1):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                    id2word=id2word,\n",
    "                    num_topics=num_topics,\n",
    "                    random_state=100,\n",
    "                    update_every=1,\n",
    "                    chunksize=200,\n",
    "                    passes=20,\n",
    "                    alpha='asymmetric',\n",
    "                    per_word_topics=True\n",
    ")\n",
    "    model_list.append(lda_model)\n",
    "    coherencemodel = CoherenceModel(model=lda_model, texts=df['clean_tok'], dictionary=id2word, coherence='c_v')\n",
    "    coherence_values.append(round(coherencemodel.get_coherence(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddbd65-3db1-43bf-bd97-137498b60081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÊúÄ‰Ω≥‰∏ªÈ¢òÊï∞ÂèØËßÜÂåñÂ±ïÁ§∫\n",
    "x = range(2,15,1)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.savefig('../Graphs/LDA_coherence_scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc59a2-7b61-4c69-9451-5efcfb5e6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â±ïÁ§∫‰∏çÂêåÁöÑ‰∏ªÈ¢òÊï∞ÂØπÂ∫îÁöÑ‰∏ÄËá¥ÊÄßÂàÜÊï∞\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c745abf-9ab0-4ca0-ae9c-4fa66aae050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê†πÊçÆ‰∏ÄËá¥ÊÄßÂæóÂàÜÔºåÈÄâÊã©ÂÖ∑ÊúâÊúÄÈ´òCVÁöÑÊ®°ÂûãÔºåÈÄâÊã©ÁöÑ‰∏ªÈ¢òÊï∞ÊòØ\n",
    "# ÈÄâÊã©Ê®°ÂûãÂπ∂ÊâìÂç∞‰∏ªÈ¢ò   \n",
    "optimal_model = model_list[8]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea76888-3403-47fd-bc40-0735f4e106f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------Âú®ÊØè‰∏™Âè•Â≠ê‰∏≠ÊâæÂà∞‰∏ªË¶ÅËØùÈ¢ò--------------------------------------------\n",
    "# ÊØè‰∏™ÊñáÊ°£ÈÉΩÂåÖÂê´Â§ö‰∏™‰∏ªÈ¢ò„ÄÇ‰ΩÜÊòØÔºåÈÄöÂ∏∏Âè™Êúâ‰∏Ä‰∏™‰∏ªÈ¢òÊòØ‰∏ªÂØºÁöÑ„ÄÇ‰∏ãÈù¢ÁöÑ‰ª£Á†Å‰∏∫ÊØè‰∏™ÊñáÊ°£ÊèêÂèñËØ•‰∏ªË¶Å‰∏ªÈ¢òÔºåÂπ∂Âú®Ê†ºÂºèÊ≠£Á°ÆÁöÑËæìÂá∫‰∏≠ÊòæÁ§∫ËØ•‰∏ªÈ¢òÁöÑÊùÉÈáç„ÄÇ\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row[0], key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0: # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                new_row = pd.DataFrame([[int(topic_num), round(prop_topic,4), topic_keywords]],\n",
    "                       columns=['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords'])\n",
    "                sent_topics_df = pd.concat([sent_topics_df, new_row], ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    # print(contents)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    # print(sent_topics_df)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d8c02-cd27-4b93-8960-01ea4b7c86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=df['fulltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db137eb6-691b-483c-9032-5bcb7e5fbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6371f3f-f76e-4968-9989-d48e71768619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "# df_dominant_topic.to_excel(path+'resultsdatas.xlsx',index=False)\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de344-ec88-49a7-9d7d-076495001fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------ÊØè‰∏™‰∏ªÈ¢ò‰∏≠ÊúÄÂÖ∑Êúâ‰ª£Ë°®ÊÄßÁöÑÂè•Â≠ê-----------------------------------------\n",
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet,\n",
    "grp.sort_values(['Perc_Contribution'], ascending=False).head(2)],\n",
    "axis=0)\n",
    "\n",
    "# Reset Index\n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265c921-bd81-4456-9b28-cebec64c7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êñá‰ª∂‰∏≠Â≠óÊï∞ÁöÑÈ¢ëÁéáÂàÜÂ∏É\n",
    "\n",
    "df_dominant_topic = df_dominant_topic.dropna(axis=0)\n",
    "doc_lens = [len(d) for d in df_dominant_topic.Text]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16,7), dpi=160)\n",
    "plt.hist(doc_lens, bins = 1000, color='navy')\n",
    "plt.text(750, 100, \"Mean : \" + str(round(np.mean(doc_lens))))\n",
    "plt.text(750, 90, \"Median : \" + str(round(np.median(doc_lens))))\n",
    "plt.text(750, 80, \"Stdev : \" + str(round(np.std(doc_lens))))\n",
    "plt.text(750, 70, \"1%ile : \" + str(round(np.quantile(doc_lens, q=0.01))))\n",
    "plt.text(750, 60, \"99%ile : \" + str(round(np.quantile(doc_lens, q=0.99))))\n",
    "\n",
    "plt.gca().set(xlim=(0, 1000), ylabel='Number of Documents', xlabel='Document Word Count')\n",
    "plt.tick_params(size=16)\n",
    "plt.xticks(np.linspace(0,1000,9))\n",
    "plt.title('Distribution of Document Word Counts', fontdict=dict(size=22))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7b33b-b702-4a66-9d8e-dac6650fb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()] # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,14), dpi=160, sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    df_dominant_topic_sub = df_dominant_topic.loc[df_dominant_topic.Dominant_Topic == i, :]\n",
    "    doc_lens = [len(d) for d in df_dominant_topic_sub.Text]\n",
    "    ax.hist(doc_lens, bins = 1000, color=cols[i])\n",
    "    ax.tick_params(axis='y', labelcolor=cols[i], color=cols[i])\n",
    "    sns.kdeplot(doc_lens, color=\"black\", shade=False, ax=ax.twinx())\n",
    "    ax.set(xlim=(0, 1000), xlabel='Document Word Count')\n",
    "    ax.set_ylabel('Number of Documents', color=cols[i])\n",
    "    ax.set_title('Topic: '+str(i), fontdict=dict(size=16, color=cols[i]))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.90)\n",
    "plt.xticks(np.linspace(0,1000,9))\n",
    "fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced8cd6-8a56-4e62-acac-68d1a7dffc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
