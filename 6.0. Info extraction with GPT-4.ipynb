{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada2d6e-59aa-4aa4-9318-541fe0b737c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "class GPTQuery:\n",
    "    system_prompt = \"\"\"You are an expert in the Chinese language and in the modern Chinese freight industry. Answer all the questions from the user as accurately as possible.\"\"\"\n",
    "    log_filename = '../gpt-query-log.txt'\n",
    "    \n",
    "    prompt: str\n",
    "    client: AsyncOpenAI\n",
    "\n",
    "    _json_locator = re.compile(r'```json(.*)```', flags=re.DOTALL)\n",
    "\n",
    "    _json_fixer: \"GPTQuery\" = None\n",
    "    _log_file = None\n",
    "\n",
    "    def __init__(self, prompt: str, system_prompt=None):\n",
    "        self.prompt = prompt\n",
    "        if system_prompt is not None:\n",
    "            self.system_prompt = system_prompt\n",
    "        with open('../Document/openai-key.txt') as fin:\n",
    "            self.client = AsyncOpenAI(api_key=fin.read().strip())\n",
    "\n",
    "    def _print_log(self, msg):\n",
    "        if self._log_file is None:\n",
    "            self._log_file = open(self.log_filename, 'a')\n",
    "            \n",
    "        self._log_file.write(str(msg))\n",
    "        self._log_file.write('\\n')\n",
    "        self._log_file.flush()\n",
    "\n",
    "    def _close_log(self):\n",
    "        if self._log_file is not None:\n",
    "            self._log_file.close()\n",
    "            del self._log_file\n",
    "\n",
    "    @classmethod\n",
    "    def _get_json_fixer(cls):\n",
    "        \"\"\"chatGPT sometimes outputs invalid json. Use itself to fix its output\"\"\"\n",
    "        if cls._json_fixer is None:\n",
    "            cls._json_fixer = cls(\n",
    "                prompt=\"\"\"The following json is invalid. Your task is to fix it to be a valid json. Your response should include the reason why it is invalid, followed by the corrected json. Do not produce any extra response after the corrected json.\"\"\",\n",
    "                system_prompt=\"\"\"You are an expert in computer science. Accurately answer the user's requests.\"\"\"\n",
    "            )\n",
    "        return cls._json_fixer\n",
    "\n",
    "    async def _auto_json_fix(self, jtxt: str) -> dict:\n",
    "        \"\"\"automatically try to fix the json response from GPT\"\"\"\n",
    "        self._print_log(f'!!!! use json fixer: {jtxt}')\n",
    "\n",
    "        if ((start_m := jtxt.find('```')) != -1 and\n",
    "            (end_m := jtxt.find('```', start_m + 3)) != -1):\n",
    "            # ChatGPT occasionally misses the json format marker\n",
    "            try:\n",
    "                return json.loads(jtxt[start_m+3:end_m])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if start_m != -1:\n",
    "            # if there are multiple jsons, use the first one\n",
    "            try:\n",
    "                return json.loads(jtxt[:start_m])\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        if '//' in jtxt:\n",
    "            # remove comments and try again\n",
    "            lines = jtxt.split('\\n')\n",
    "            for i, j in enumerate(lines):\n",
    "                if (cmt_m := j.find('//')) != -1 and '\"' not in j[cmt_m:]:\n",
    "                    lines[i] = j[:cmt_m]\n",
    "            try:\n",
    "                return json.loads('\\n'.join(lines))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        fixer = self._get_json_fixer()\n",
    "        assert self is not fixer  # avoid infinite recursion\n",
    "        return await fixer._query(jtxt)\n",
    "\n",
    "    async def _query(self, query: str) -> dict:\n",
    "        resp = await self.client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{self.prompt}\\n\\n{query}\"}\n",
    "            ]\n",
    "        )\n",
    "        msg = resp.choices[0].message\n",
    "        try:\n",
    "            assert msg.role == 'assistant' and msg.function_call is None and msg.tool_calls is None\n",
    "            self._print_log('============')\n",
    "            self._print_log(query)\n",
    "            txt = msg.content\n",
    "            jtxt_m = self._json_locator.search(txt)\n",
    "            if jtxt_m is None:\n",
    "                jtxt = txt  # gpt sometimes does not wrap the result in json blocks\n",
    "            else:\n",
    "                jtxt = jtxt_m.group(1)\n",
    "            try:\n",
    "                json_succ = False\n",
    "                ret = json.loads(jtxt)\n",
    "                json_succ = True\n",
    "            except:\n",
    "                ret = await self._auto_json_fix(jtxt)\n",
    "                \n",
    "            self._print_log(json.dumps(ret, ensure_ascii=False, indent=2))\n",
    "            if jtxt_m is None or jtxt_m.group(0) != txt or not json_succ:\n",
    "                ret['original_resp'] = txt\n",
    "        except Exception as exc:\n",
    "            raise RuntimeError(f'Query: {query}\\nResp: {msg}') from exc\n",
    "        return ret\n",
    "        \n",
    "    async def query(self, query: str) -> dict:\n",
    "        \"\"\"query a single input, asynchronously\"\"\"\n",
    "        try:\n",
    "            return await self._query(query)\n",
    "        finally:\n",
    "            self._close_log()\n",
    "\n",
    "    async def batch_query(self, concurrency: int, result_file: Path, queries: dict[str, str]):\n",
    "        \"\"\"query multiple inputs concurrently and asynchrously.\n",
    "\n",
    "        :param concurrency: number of concurrent queries allowed\n",
    "        :param result_file: json file to save the results; when a new result arrives, it will be saved immediately. The old result will be read\n",
    "        :param queries: a dict of the queries\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(result_file, Path):\n",
    "            result_file = Path(result_file)\n",
    "\n",
    "        if result_file.exists():\n",
    "            with result_file.open() as fin:\n",
    "                result = json.load(fin)\n",
    "                print(f'Loaded {len(result)} results')\n",
    "        else:\n",
    "            result = {}\n",
    "\n",
    "        def save_result(force=False):\n",
    "            if (not force) and len(result) % concurrency:\n",
    "                # only save when we get a new batch of results to speed up\n",
    "                return\n",
    "            if result_file.exists():\n",
    "                result_file.rename(result_file.with_suffix('.json.bak'))\n",
    "            with result_file.open('w') as fout:\n",
    "                json.dump(result, fout, ensure_ascii=False, indent=2)\n",
    "            self._print_log(f'******* saved {len(result)} results')\n",
    "\n",
    "        async def one_task(qid):\n",
    "            qres = await self._query(queries[qid])\n",
    "            result[qid] = qres\n",
    "            save_result()\n",
    "\n",
    "        queries = {str(k): v for k, v in queries.items()}\n",
    "        tasks = [one_task(k) for k in queries.keys() if k not in result]\n",
    "\n",
    "        try:\n",
    "            with tqdm(total=len(queries)) as pbar:\n",
    "                pbar.update(len(result))\n",
    "                async for i in self._limit_concurrency(tasks, concurrency):\n",
    "                    await i\n",
    "                    pbar.update(1)\n",
    "        finally:\n",
    "            save_result(True)\n",
    "            self._close_log()\n",
    "\n",
    "    @classmethod\n",
    "    async def _limit_concurrency(cls, aws, limit):\n",
    "        \"\"\"run awaitables with limited concurrency\"\"\"\n",
    "        # see https://death.andgravity.com/limit-concurrency#asyncio-wait\n",
    "        aws = iter(aws)\n",
    "        aws_ended = False\n",
    "        pending = set()\n",
    "    \n",
    "        while pending or not aws_ended:\n",
    "            while len(pending) < limit and not aws_ended:\n",
    "                try:\n",
    "                    aw = next(aws)\n",
    "                except StopIteration:\n",
    "                    aws_ended = True\n",
    "                else:\n",
    "                    pending.add(asyncio.ensure_future(aw))\n",
    "    \n",
    "            if not pending:\n",
    "                return\n",
    "    \n",
    "            done, pending = await asyncio.wait(\n",
    "                pending, return_when=asyncio.FIRST_COMPLETED\n",
    "            )\n",
    "            while done:\n",
    "                yield done.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e778b63-d74d-4d71-8ff8-e8ed69529221",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\n",
    "    \"\"\"You will be given a social media post in Chinese language. These texts involve truck drivers’ experiences or opinions about freight transportation platforms. Possible freight platform names include yunmanman(运满满)、huochebang (货车帮)、huolala (货拉拉)、and manbang (满帮). Please keep in mind that abbreviations, homophones, symbols, and placeholders may also be used to avoid direct mentioning of platform names. \n",
    "Based on this text, You need to complete two tasks:\n",
    "\n",
    "1.\tSummarize the main topic of the text;\n",
    "2.\tOn a scale of 1-7, evaluate how positive or negative are truck drivers’ sentiments towards these platforms? A score of 1 means \"very negative\". A score of 7 means \"very positive\". \n",
    "\n",
    "IMPORTANT: If the text is too short or seems incomplete for a useful evaluation, then use 4 as the score. If you can not evaluate the sentiment, provide the reason and use 4 as the score. The text provided later is already the complete post. NEVER ask for more text.\n",
    "\n",
    "Your response should be in English.\n",
    "\n",
    "Your response must be in well-formed JSON format, with three keys as decribed below:\n",
    "\n",
    "- \"reason\": a string that summarizes your reasoning about the topic and the sentiment score; \n",
    "- \"topic\": a string that summarizes the main topic of the text;\n",
    "- \"result\": an integer, the sentiment score of the text\n",
    "\n",
    "Below is the text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('../processed_data/clean_data_final.parquet')\n",
    "\n",
    "queries = {row['tid']: row['fulltext'] for _, row in df.iterrows()}\n",
    "\n",
    "# await gpt_query.batch_query(32, '../sentiment_and_topic.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad04eb8-6765-4db1-bda1-7dfae634e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\n",
    "    \"\"\"You will be given a corpus that contains multiple sentences with indexes. The sentences are separated by line breaks. These sentences are automatically-generated summarizations of social media posts involving truck drivers' experiences or opinions about freight transportation platforms. Possible freight platform names include yunmanman(运满满)、huochebang (货车帮)、huolala (货拉拉)、and manbang (满帮). The text may be a mixture of English or Chinese.\n",
    "\n",
    "Your task is to categorize them based on their content, focusing on recurring themes or issues mentioned. Please identify 5 to 10 common topics from these sentences. The topics should be specific. Each sentence should have a corresponding topic. \n",
    "\n",
    "Your response should be in English.\n",
    "\n",
    "Your response must be in well-formed JSON format that is a list containing multiple dicts, where each dict corresponds to one topic you identified. Each dict should have three keys as described below:\n",
    "\n",
    "- \"explanation\": a string that explains the topic and your reasoning for giving the topic;\n",
    "- \"topic\": a string shows the name of the topic; \n",
    "- \"indexes\": a list that contains the indexes of 5 sentences that best illustrate this topic.\n",
    "\n",
    "Below is the text for analysis:\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('../processed_data/grouped_corpus.pkl')\n",
    "\n",
    "def make_query(group):\n",
    "    return '\\n'.join(f'{i}: {j}' for i, j in sorted(group.items()))\n",
    "\n",
    "queries = {row['group']: make_query(row['corpus']) for _, row in df.iterrows()}\n",
    "\n",
    "# await gpt_query.batch_query(8, '../topic_group.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a67c4f-0a0b-4c11-9b84-5e189e58199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_query = GPTQuery(\n",
    "\"\"\"You will be given a social media post in Chinese language. The topic of the text is about freight transportation platforms. Possible freight platform names include yunmanman(运满满), huochebang (货车帮), huolala (货拉拉), and manbang (满帮). Abbreviations, homophones, symbols, and placeholders may also be used to avoid directly mentioning platform names. \n",
    "\n",
    "Here is the list of themes to which the given text may belong. The theme's definition is given following the colon. \n",
    "\n",
    "1. Financial Considerations: This theme encompasses discussions about the financial aspects of freight platforms, including platform fees, pricing and rates, payment, earnings, profitability, and other financial considerations of truck drivers.\n",
    "\n",
    "2. Fraud, Scams, Privacy, and Security: This theme addresses fraudulent activities, scams, and discussions about data privacy and information security on freight platforms.\n",
    "\n",
    "3. Regulatory and Legal Prospects: This theme involves discussions on the government’s regulatory practices and calls for regulatory oversight, compliance enforcement, and government intervention in the freight transportation industry.\n",
    "\n",
    "4. Community Engagement and Solidarity: This theme involves community and solidarity among truck drivers, including sharing experiences, advice, and mutual support among truck drivers, as well as collective actions and boycotts against platforms.\n",
    "\n",
    "5. Vehicle Selection and Purchase Strategies: This theme focuses on discussions and advice on selecting and purchasing vehicles for freight platforms.\n",
    "\n",
    "6. Inquiries and Advice for Platform Usage: This theme involves inquiries and advice regarding the practical and operational aspects of working with freight platforms, including strategies for navigating platform policies and solving technical problems.\n",
    "\n",
    "7. Evaluation of Platform Service Quality: This theme includes truck drivers' experiences working with freight transportation platforms and their evaluations of different platforms, focusing on customer support, service quality, and overall satisfaction.\n",
    "\n",
    "8. General Discussions of Freight Industry and Job Market: This theme involves discussions on the overall situations of the freight transportation industry and the job market for truck drivers, including technological adoptions, market competition, and challenges for job seekers, etc.\n",
    "\n",
    "You have two tasks. Your first task is to evaluate the relevance scores of the eight themes that describe how well each theme matches the given text. Each score should be an integer between 0 and 9. You should provide eight scores corresponding to each theme. Your second task is to determine which one of the above eight themes BEST describes the topic of the given text. You should respond by providing the number corresponding to the best-matching theme. \n",
    "\n",
    "The provided text is always complete. NEVER ask for more text. If the text is too short or incomplete for your analysis, please use -1 as the best matching theme's number and an empty list as the relevance score.\n",
    "\n",
    "Your response must be in well-formed JSON format that is a dictionary containing three keys described below:\n",
    "- \"explanation\": a string that explains your understanding of the given text's content and your reasoning of giving the relevance scores.\n",
    "- \"scores\": a list of integers as the relevance scores of the themes.\n",
    "- \"theme\": an integer that represents the theme the given text belongs to.\n",
    "\n",
    "Make sure that your response is well-formated. Avoid the mistake of including comments in the scores list in the JSON.\n",
    "\n",
    "Below is the text for analysis:\"\"\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('../processed_data/with_gpt_results.parquet')\n",
    "\n",
    "queries = {row['tid']: row['fulltext'] for _, row in df.iterrows()}\n",
    "\n",
    "# await gpt_query.batch_query(32, '../theme_categorization.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e5db6-1a4f-460c-b51e-9e191a1e4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sub-themes\n",
    "with open('../prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "prompts = [i.strip().replace('\\xa0', '') for i in prompt.split('--------------------')]\n",
    "assert len(prompts) == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5fc5d-1955-48a2-849b-2a90a5918355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('theme_with_chunks.pkl', 'rb') as fin:\n",
    "    data = pickle.load(fin)\n",
    "assert len(data) == len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c091965-fa4c-4b76-add2-35592e2b3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme_id in range(len(prompts)):\n",
    "    print(f'working on {theme_id} ...')\n",
    "    queries = {}\n",
    "    for _, row in data[theme_id].iterrows():\n",
    "        assert row['theme'] == theme_id + 1\n",
    "        queries[f\"{row['theme']}.{row['chunk_no']}\"] = make_query(row['corpus'])\n",
    "    gpt_query = GPTQuery(prompts[theme_id])\n",
    "    await gpt_query.batch_query(32, f'../subthemes-{theme_id+1}.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d53783-b3fd-439e-b1d4-cc6061dd5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune themes\n",
    "\n",
    "gpt_query = GPTQuery(\n",
    "\"\"\"You will be given a social media post in Chinese language. The topic of the text is about freight transportation platforms. Possible freight platform names include yunmanman(运满满), huochebang (货车帮), huolala (货拉拉), and manbang (满帮). Abbreviations, homophones, symbols, and placeholders may also be used to avoid directly mentioning platform names. \n",
    "\n",
    "Here is the list of themes to which the given text may belong. The theme's definition is given following the colon. \n",
    "\n",
    "1. Vehicle selection and platform evaluation: This theme focuses on inquiries and discussions on selecting and purchasing vehicles and on the economic viability of different freight platforms, showing truck drivers' interest in entering the market through platforms. \n",
    "\n",
    "2. Shipping prices and Profitability on Platforms: This theme focuses on discussions on shipping prices and freight order availabilities on platforms, possible causes for low shipping prices and market downturn, and their impacts on truck drivers' earnings and livelihood.\n",
    "\n",
    "3. Platform Fees and Service Issues: This theme focuses on platform payment issues (fees, charges, refund, etc.), strategies for nagivating platform features, and truck drivers' experience interacting with platform customer service.\n",
    "\n",
    "4. Fraudulence, disputes, and platform mediation: This theme focuses on truck drivers' experience of fraudulence, scams, delayed payment, or nonpayment issues by freight owners and platforms' practices in resolving disputes and complaints.\n",
    "\n",
    "5. Regulation and Governance: This theme involves truck drivers' discussions on state activities or policies in regulating freight platforms and comments on the effectiveness of government intervention. \n",
    "\n",
    "6. Community and Solidarity: This theme highlights the importance of community and solidarity among truck drivers, including sharing experiences, advice, and mutual support among truck drivers, as well as collective actions and boycotts against platforms.\n",
    "\n",
    "7. General Discussions on Industry and Platforms: This theme involves discussions on the overall situations of the freight transportation industry (such as technological changes, market competition, and challenges for job seekers) and other general discussions on platforms.\n",
    "\n",
    "You have two tasks. Your first task is to evaluate the relevance scores of the seven themes that describe how well each theme matches the given text. Each score should be an integer between 0 and 9. You should provide seven scores corresponding to each theme. Your second task is to determine which one of the above seven themes BEST describes the topic of the given text. You should respond by providing the number corresponding to the best-matching theme. \n",
    "\n",
    "The provided text is always complete. NEVER ask for more text. If the text is too short or too vague that you find challenging to assign a theme, please use -1 as the best matching theme's number and an empty list as the relevance score.\n",
    "\n",
    "Your response must be in well-formed JSON format that is a dictionary containing three keys described below:\n",
    "- \"explanation\": a string that explains your understanding of the given text's content and your reasoning of giving the relevance scores.\n",
    "- \"scores\": a list of integers as the relevance scores of the themes.\n",
    "- \"theme\": an integer that represents the theme the given text belongs to.\n",
    "\n",
    "Make sure that your response is well-formated. Avoid the mistake of including comments in the scores list in the JSON. Remeber to escape the quotes in JSON strings if needed.\n",
    "\n",
    "Below is the text for analysis:\"\"\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('../processed_data/with_gpt_results.parquet')\n",
    "\n",
    "queries = {row['id']: row['fulltext'] for _, row in df.iterrows()}\n",
    "\n",
    "await gpt_query.batch_query(32, '../theme_categorization_2nd_round.json', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44dedec-1428-424d-8919-5cd84ba4911d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = '\\n{\\n  \"explanation\": \"The text is inquiring about the viability and profitability of running a 6.8-meter high fence truck on the Yunmanman platform. The phrase \\'干得来吃吗？\\' is colloquially asking if it is profitable or feasible to work (\"干\") with such a vehicle on this specific freight platform. The user is seeking advice from experienced truck drivers (\\'各位大神们\\') about entering the market, specifically focusing on vehicle selection for the Yunmanman platform.\",\\n  \"scores\": [8, 2, 0, 0, 0, 0, 2],\\n  \"theme\": 1\\n}\\n'\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
